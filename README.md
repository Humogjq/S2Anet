# SÂ²A-Net: Spatially Self-Aware Multitask Network for Joint Retinal Structure Segmentation

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/pytorch-1.10%2B-orange)](https://pytorch.org/)

Official implementation of **SÂ²A-Net**, a unified CNN-Transformer framework for joint segmentation of retinal vessels (RV) and foveal avascular zone (FAZ) in OCTA images. Achieves state-of-the-art performance through spatial self-awareness and dynamic task balancing.

![S2A-Net Architecture](docs/network.png)  
*Figure: Overall architecture of SÂ²A-Net (Illustration suggested)*

## ğŸ“– Introduction
Accurate segmentation of retinal structures is crucial for ophthalmic biomarker analysis. Existing methods either:
- âŒ **Independently** segment RV/FAZ (ignoring anatomical relationships)
- âŒ Use **rigid joint-learning** (failing to balance task competition)

**Our Solution**:  
**SÂ²A-Net** introduces:
1. **Spatial Self-Awareness**: Unified Transformer-CNN framework modeling retinal structure relationships
2. **Dynamic Weight Balancing**: Sinusoidal-based loss adaptation for task coordination
3. **Context-Aware Modules**: Task-specific feature refinement (LCEM/GCEM)

**Key Advantages**:
- ğŸ† **91.82% RV Dice** | **98.54% FAZ Dice** on OCTA-500
- âœ¨ Superior microvascular segmentation near FAZ boundaries
- âš¡ Flexible integration with existing encoder-decoder architectures

## ğŸš€ Key Features
- **Multi-Scale Semantic Extraction**: Hybrid CNN-Transformer backbone captures local details and global dependencies
- **Task-Specific Context Exchange**:
  - **LCEM**: Local vascular pattern refinement
  - **GCEM**: Global FAZ boundary reasoning
- **Dynamic Weight Balancing (DWB)**:
  ```python
  Î± = 0.1 + 0.8*sin(epoch_progress) + 0.1*(loss_ratio)  # Dynamic task weighting


## ğŸ“Š Performance Highlights

- For OCTA-500 Dataset

- Method	RV Dice (%)	FAZ Dice (%)
- U-Net	88.23	95.69
- TransUNet	90.06	97.39
- Joint-Seg	90.35	98.05
- SÂ²A-Net	90.82	98.54

- 
- FAZ Perivascular Region
- Method	OCTA-500	ROSE-H
- VAFF-Net	97.68	79.64
- SÂ²A-Net	98.64	81.23


ğŸš€ Quick Start
Installation

# Clone repo
git clone https://github.com/yourname/S2A-Net.git
cd S2A-Net

# Create conda env (recommended)
conda create -n s2anet python=3.8
conda activate s2anet

# Install dependencies
pip install -r requirements.txt
Data Preparation
Download datasets from OCTA-500 and ROSE

Organize folder structure:

data/
â”œâ”€â”€ octa500/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â””â”€â”€ masks/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ images/
â”‚       â””â”€â”€ masks/
â””â”€â”€ rose/
    â”œâ”€â”€ O/
    â”œâ”€â”€ Z/
    â””â”€â”€ H/
Training
bash
å¤åˆ¶
# Single GPU training
python train.py --config configs/octa500.yaml --gpus 1

# Multi-GPU training (example)
python train.py --config configs/rose.yaml --gpus 4 --accelerator ddp
Inference
python

from models import S2ANet

# Load pretrained model
model = S2ANet.load_from_checkpoint("checkpoints/best_model.ckpt")

# Predict on OCTA image
import cv2
img = cv2.imread("sample.png", 0)  # Grayscale
rv_mask, faz_mask = model.predict(img)

# Visualization
import matplotlib.pyplot as plt
plt.imshow(img, cmap='gray')
plt.imshow(rv_mask, alpha=0.5)  # Overlay RV prediction
plt.show()
ğŸ“Š Performance Highlights
Quantitative Results (Dice %)
Dataset	Method	RV	FAZ
OCTA-500	U-Net	88.23	95.69
TransUNet	90.06	97.39
SÂ²A-Net	90.82	98.54
ROSE-H	Joint-Seg	79.63	81.00
SÂ²A-Net	81.36	81.41
FAZ Perivascular Performance
Region Size	Method	Dice
120Ã—120 px	VAFF-Net	79.64
SÂ²A-Net	81.23
Comparison Visualization

ğŸ“š Citation
If you use this work in your research, please cite:

bibtex

@inproceedings{s2anet2023,
  title={Spatially Self-Aware Multitask Network for Joint Segmentation of Retinal Vasculature and Foveal Avascular Zone in OCTA Images},
  author={Your Name and Co-authors},
  booktitle={Medical Image Computing and Computer Assisted Intervention},
  year={2023},
  pages={1--11}
ğŸ“ License
This project is licensed under the MIT License - see the LICENSE file for details.

Clinical Applications:

Early detection of diabetic retinopathy ğŸ©¸

Glaucoma progression monitoring ğŸ‘ï¸

Alzheimer's disease biomarkers ğŸ§ 

Acknowledgments: This work was supported by [Your Funding Source] under Grant [XXXXXXX].

